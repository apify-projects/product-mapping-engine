"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.requestAsBrowser = void 0;
const gotScraping = require("got-scraping");
const ow_1 = require("ow");
const utils_log_1 = require("./utils_log");
/* eslint-enable no-unused-vars,import/named,import/order */
/**
 * @typedef {(IncomingMessage & Readable & { body: string })} RequestAsBrowserResult
 */
/**
 * @typedef RequestAsBrowserOptions
 * @property {string} url
 *  URL of the target endpoint. Supports both HTTP and HTTPS schemes.
 * @property {string} [method="GET"]
 *  HTTP method.
 * @property {Object<string, string>} [headers]
 *  Additional HTTP headers to add. It's only recommended to use this option,
 *  with headers that are typically added by websites, such as cookies. Overriding
 *  default browser headers will remove the masking this function provides.
 * @property {string} [proxyUrl]
 *  An HTTP proxy to be passed down to the HTTP request. Supports proxy authentication with Basic Auth.
 * @property {object} [headerGeneratorOptions]
 *  Configuration to be used for generating correct browser headers.
 *  See the [`header-generator`](https://github.com/apify/header-generator) library.
 * @property {string} [languageCode=en]
 *  Two-letter ISO 639 language code.
 * @property {string} [countryCode=US]
 *  Two-letter ISO 3166 country code.
 * @property {boolean} [useMobileVersion]
 *  If `true`, the function uses User-Agent of a mobile browser.
 * @property {boolean} [ignoreSslErrors=true]
 *  If set to true, SSL/TLS certificate errors will be ignored.
 * @property {boolean} [useInsecureHttpParser=true]
 *  Node.js' HTTP parser is stricter than parsers used by web browsers, which prevents scraping of websites
 *  whose servers do not comply with HTTP specs, either by accident or due to some anti-scraping protections,
 *  causing e.g. the `invalid header value char` error. The `useInsecureHttpParser` option forces
 *  the HTTP parser to ignore certain errors which lets you scrape such websites.
 *  However, it will also open your application to some security vulnerabilities,
 *  although the risk should be negligible as these vulnerabilities mainly relate to server applications, not clients.
 *  Learn more in this [blog post](https://snyk.io/blog/node-js-release-fixes-a-critical-http-security-vulnerability/).
 * @property {AbortFunction} [abortFunction]
 *  Function accepts `response` object as a single parameter and should return `true` or `false`.
 *  If function returns true, request gets aborted.
 * @property {boolean} [useHttp2=true]
 *  If set to false, it will prevent use of HTTP2 requests. This is strongly discouraged. Websites
 *  expect HTTP2 connections, because browsers use HTTP2 by default. It will automatically downgrade
 *  to HTTP/1.1 for websites that do not support HTTP2. For Node 10 this option is always set to `false`
 *  because Node 10 does not support HTTP2 very well. Upgrade to Node 12 for better performance.
 * @property {boolean} [forceUrlEncoding]
 *   Automatically encode URLs via `encodeURI()` before resolving them.
 */
/**
 * @callback AbortFunction
 * @param {IncomingMessage} response
 * @returns {boolean}
 */
/**
 * **IMPORTANT:** This function uses an insecure version of HTTP parser by default
 * and also ignores SSL/TLS errors. This is very useful in scraping, because it allows bypassing
 * certain anti-scraping walls, but it also exposes some vulnerability. For other than scraping
 * scenarios, please set `useInsecureHttpParser: false` and `ignoreSslErrors: false`.
 *
 * Sends a HTTP request that looks like a request sent by a web browser,
 * fully emulating browser's HTTP headers. It uses HTTP2 by default for Node 12+.
 *
 * This function is useful for web scraping of websites that send the full HTML in the first response.
 * Thanks to this function, the target web server has no simple way to find out the request
 * hasn't been sent by a human's web browser. Using a headless browser for such requests
 * is an order of magnitude more resource-intensive than this function.
 *
 * The function emulates the Chrome and Firefox web browsers. If you want more control
 * over the browsers and their versions, use the `headerGeneratorOptions` property.
 * You can find more info in the readme of the [`header-generator`](https://github.com/apify/header-generator) library.
 *
 * Internally, the function uses the [`got-scraping`](https://github.com/apify/got-scraping) library to perform the request.
 * All `options` not recognized by this function are passed to it so see it for more details.
 *
 * **Example usage:**
 * ```js
 * const Apify = require('apify');
 *
 * const { utils: { requestAsBrowser } } = Apify;
 *
 * ...
 *
 * const response = await requestAsBrowser({ url: 'https://www.example.com/' });
 *
 * const html = response.body;
 * const status = response.statusCode;
 * const contentType = response.headers['content-type'];
 * ```
 *
 * @param {RequestAsBrowserOptions} options All `requestAsBrowser` configuration options.
 *
 * @return {Promise<RequestAsBrowserResult>} The result can be various objects, but it will always be like a
 * [Node.js HTTP response stream](https://nodejs.org/api/http.html#http_class_http_incomingmessage)
 * with a 'body' property for the parsed response body, unless the 'stream' option is used.
 * @memberOf utils
 * @name requestAsBrowser
 * @function
 */
const requestAsBrowser = async (options = {}) => {
    logDeprecatedOptions(options);
    ow_1.default(options, 'RequestAsBrowserOptions', ow_1.default.object.partialShape({
        payload: ow_1.default.optional.any(ow_1.default.string, ow_1.default.buffer),
        proxyUrl: ow_1.default.optional.string.url,
        languageCode: ow_1.default.optional.string.length(2),
        countryCode: ow_1.default.optional.string.length(2),
        useMobileVersion: ow_1.default.optional.boolean,
        abortFunction: ow_1.default.optional.function,
        ignoreSslErrors: ow_1.default.optional.boolean,
        useInsecureHttpParser: ow_1.default.optional.boolean,
        useHttp2: ow_1.default.optional.boolean,
        timeoutSecs: ow_1.default.optional.number,
        throwOnHttpErrors: ow_1.default.optional.boolean,
        headerGeneratorOptions: ow_1.default.optional.object,
        stream: ow_1.default.optional.boolean,
        decodeBody: ow_1.default.optional.boolean,
        forceUrlEncoding: ow_1.default.optional.boolean,
    }));
    ow_1.default(options, 'RequestAsBrowserOptions', ow_1.default.object.validate((opts) => ({
        validator: areBodyOptionsCompatible(opts),
        message: (label) => `The 'payload', 'body', 'json' and 'form' options of ${label} are mutually exclusive.`,
    })));
    // We created the `got-scraping` package which replaced underlying @apify/http-request.
    // At the same time, we want users to be able to use requestAsBrowser without breaking changes.
    // So we do a lot of property mapping here, to make sure that everything works as expected.
    // TODO Update this with SDK v2 and use `got-scraping` API directly.
    const { payload, // alias for body to allow direct passing of our Request objects
    proxyUrl, json, headerGeneratorOptions, languageCode = 'en', countryCode = 'US', useMobileVersion = false, abortFunction = () => false, ignoreSslErrors = true, useInsecureHttpParser = true, useHttp2 = true, timeoutSecs = 30, throwOnHttpErrors = false, stream = false, decodeBody = true, forceUrlEncoding, ...gotParams } = options;
    const gotScrapingOptions = {
        proxyUrl,
        insecureHTTPParser: useInsecureHttpParser,
        http2: useHttp2,
        timeout: timeoutSecs * 1000,
        throwHttpErrors: throwOnHttpErrors,
        isStream: stream,
        decompress: decodeBody,
        // We overwrite the above arguments because we want to give the official
        // got interface a priority over our requestAsBrowser one.
        // E.g. { isStream: false, stream: true } should produce { isStream: false }.
        ...gotParams,
    };
    // TODO remove when we drop support for Node 10
    ensureValidConfigForNode10(gotScrapingOptions);
    // Order is important for payload and json.
    normalizePayloadOption(payload, gotScrapingOptions);
    normalizeJsonOption(json, gotScrapingOptions);
    normalizeSslErrorHandling(ignoreSslErrors, gotScrapingOptions);
    ensureCorrectHttp2Headers(gotScrapingOptions);
    maybeAddAbortHook(abortFunction, gotScrapingOptions);
    if (!headerGeneratorOptions) {
        // Values that respect old requestAsBrowser user-agents and settings
        gotScrapingOptions.headerGeneratorOptions = {
            devices: useMobileVersion ? ['mobile'] : ['desktop'],
            locales: [`${languageCode}-${countryCode}`],
        };
    }
    else {
        gotScrapingOptions.headerGeneratorOptions = headerGeneratorOptions;
    }
    if (forceUrlEncoding) {
        gotScrapingOptions.url = encodeURI(gotScrapingOptions.url);
    }
    if (!gotScrapingOptions.isStream) {
        return gotScraping(gotScrapingOptions);
    }
    // abortFunction must be handled separately for streams :(
    const duplexStream = await gotScraping(gotScrapingOptions);
    ensureRequestIsDispatched(duplexStream, gotScrapingOptions);
    return new Promise((resolve, reject) => {
        duplexStream
            .on('error', reject)
            .on('response', (res) => {
            try {
                const shouldAbort = abortFunction(res);
                if (shouldAbort) {
                    const err = new Error(`Request for ${gotScrapingOptions.url} aborted due to abortFunction.`);
                    duplexStream.destroy(err);
                    return reject(err);
                }
            }
            catch (e) {
                duplexStream.destroy(e);
                return reject(e);
            }
            addResponsePropertiesToStream(duplexStream, res);
            return resolve(duplexStream);
        });
    });
};
exports.requestAsBrowser = requestAsBrowser;
function ensureValidConfigForNode10(gotScrapingOptions) {
    if (process.version.startsWith('v10')) {
        if (gotScrapingOptions.http2 === true) {
            // Using log.deprecated to log only once.
            utils_log_1.default.deprecated('utils.requestAsBrowser does not support HTTP2 on Node 10. Please upgrade to Node 12+ or set useHttp2 to false.');
        }
        gotScrapingOptions.http2 = false;
        gotScrapingOptions.ciphers = undefined;
    }
}
/**
 * `got` has a `body` option and 2 helpers, `json` and `form`, to provide specific bodies.
 * Those options are mutually exclusive. `requestAsBrowser` also supports `payload` as
 * an alias of `body`. It must be exclusive as well.
 * @param {RequestAsBrowserOptions} requestAsBrowserOptions
 * @return {boolean}
 * @private
 * @ignore
 */
function areBodyOptionsCompatible(requestAsBrowserOptions) {
    const { payload, json, body, form } = requestAsBrowserOptions;
    // A boolean is old requestAsBrowser interface and not a real "body"
    // See the normalizeJsonOption function.
    const jsonBody = typeof json === 'boolean' ? undefined : json;
    const possibleOpts = [payload, jsonBody, body, form];
    const usedOpts = possibleOpts.filter((opt) => opt !== undefined);
    // Only a single option out of the 4 can be used.
    return usedOpts.length <= 1;
}
/**
 * got-scraping uses 'body', but we also support 'payload' from {@link Request}.
 * @param {string|Buffer} payload
 * @param {GotScrapingOptions} gotScrapingOptions
 * @ignore
 * @private
 */
function normalizePayloadOption(payload, gotScrapingOptions) {
    if (payload !== undefined)
        gotScrapingOptions.body = payload;
}
/**
 * `json` is a boolean flag in `requestAsBrowser`, but a `body` alias that
 * adds a 'content-type: application/json' header in got. To stay backwards
 * compatible we need to figure out which option the user provided.
 * @param {*} json
 * @param {GotScrapingOptions} gotScrapingOptions
 * @ignore
 * @private
 */
function normalizeJsonOption(json, gotScrapingOptions) {
    // If it's a boolean, then it's the old requestAsBrowser API.
    // If it's true, it means the user expects a JSON response.
    if (json === true) {
        gotScrapingOptions.responseType = 'json';
        gotScrapingOptions.ciphers = undefined;
    }
    else if (json === false) {
        // Do nothing, it means the user expects something else than JSON.
    }
    else {
        // If it's something else, we let `got` handle it as a request body.
        gotScrapingOptions.json = json;
    }
}
/**
 * @param {boolean} ignoreSslErrors
 * @param {GotScrapingOptions} gotScrapingOptions
 * @ignore
 * @private
 */
function normalizeSslErrorHandling(ignoreSslErrors, gotScrapingOptions) {
    if (gotScrapingOptions.https) {
        gotScrapingOptions.https.rejectUnauthorized = !ignoreSslErrors;
    }
    else {
        gotScrapingOptions.https = { rejectUnauthorized: !ignoreSslErrors };
    }
}
/**
 * 'connection' and 'host' headers are forbidden when using HTTP2. We delete
 * them from user-provided headers because we switched the default from HTTP1 to 2.
 * @param {GotScrapingOptions} gotScrapingOptions
 * @ignore
 * @private
 */
function ensureCorrectHttp2Headers(gotScrapingOptions) {
    var _a, _b, _c, _d;
    if (gotScrapingOptions.http2) {
        (_a = gotScrapingOptions.headers) === null || _a === void 0 ? true : delete _a.connection;
        (_b = gotScrapingOptions.headers) === null || _b === void 0 ? true : delete _b.Connection;
        (_c = gotScrapingOptions.headers) === null || _c === void 0 ? true : delete _c.host;
        (_d = gotScrapingOptions.headers) === null || _d === void 0 ? true : delete _d.Host;
    }
}
/**
 * `abortFunction` is an old `requestAsBrowser` interface for aborting requests before
 * the response body is read to save bandwidth.
 * @param {function} abortFunction
 * @param {GotScrapingOptions} gotScrapingOptions
 * @ignore
 * @private
 */
function maybeAddAbortHook(abortFunction, gotScrapingOptions) {
    // Stream aborting must be handled on the response object because `got`
    // does not execute `afterResponse` hooks for streams :(
    if (gotScrapingOptions.isStream)
        return;
    const abortHook = (response) => {
        const shouldAbort = abortFunction(response);
        if (shouldAbort) {
            throw new Error(`Request for ${gotScrapingOptions.url} aborted due to abortFunction.`);
        }
        return response;
    };
    const abortRequestOptions = {
        hooks: {
            afterResponse: [abortHook],
        },
    };
    gotScrapingOptions = gotScraping.mergeOptions(gotScraping.defaults.options, gotScrapingOptions, abortRequestOptions);
}
/**
 * 'got' will not dispatch non-GET request stream until a body is provided.
 * @param {stream.Duplex} duplexStream
 * @param {GotScrapingOptions} gotScrapingOptions
 */
function ensureRequestIsDispatched(duplexStream, gotScrapingOptions) {
    const { method } = gotScrapingOptions;
    const bodyIsEmpty = gotScrapingOptions.body === undefined
        && gotScrapingOptions.json === undefined
        && gotScrapingOptions.form === undefined;
    if (method && method.toLowerCase() !== 'get' && bodyIsEmpty) {
        duplexStream.end();
    }
}
/**
 * @param {RequestAsBrowserOptions} options
 * @ignore
 * @private
 */
function logDeprecatedOptions(options) {
    const deprecatedOptions = ['languageCode', 'countryCode', 'useMobileVersion'];
    for (const deprecatedOption of deprecatedOptions) {
        if (options.hasOwnProperty(deprecatedOption)) {
            utils_log_1.default.deprecated(`"options.${deprecatedOption}" is deprecated. Use "options.headerGeneratorOptions" instead.`);
        }
    }
}
/**
 * The stream object returned from got does not have the below properties.
 * At the same time, you can't read data directly from the response stream,
 * because they won't get emitted unless you also read from the primary
 * got stream. To be able to work with only one stream, we move the expected props
 * from the response stream to the got stream.
 * @param {GotStream} stream
 * @param {http.IncomingMessage} response
 * @return {GotStream}
 * @ignore
 * @private
 */
function addResponsePropertiesToStream(stream, response) {
    const properties = [
        'statusCode', 'statusMessage', 'headers',
        'complete', 'httpVersion', 'rawHeaders',
        'rawTrailers', 'trailers', 'url',
        'request',
    ];
    properties.forEach((prop) => {
        if (stream[prop] === undefined) {
            stream[prop] = response[prop];
        }
    });
    return stream;
}
